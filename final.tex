%++++++++++++++++++++++++++++++++++++++++
\documentclass[article, 11pt]{article}
\usepackage{float}
\usepackage{setspace}
\usepackage{tabu} % extra features for tabular environment
\usepackage{amsmath}  % improve math presentation
\usepackage{graphicx} % takes care of graphic including machinery
\usepackage[margin=1in]{geometry} % decreases margins
\usepackage{cite} % takes care of citations
\usepackage[final]{hyperref} % adds hyper links inside the generated pdf file
\usepackage{tikz}
\usepackage{caption} 
\usepackage{fancyhdr}
\usepackage{amssymb} % symbols like /therefore
\usepackage{amsthm} % proofs
\usepackage{enumerate} % lettered lists
\usepackage{mathtools} % macros
\usepackage{hyperref} % hyperlinks
\usetikzlibrary{scopes}
\usepackage{xcolor} \pagecolor[rgb]{0.12549019607,0.1294117647,0.13725490196} \color[rgb]{0.82352941176,0.76862745098,0.62745098039} % dark theme
\theoremstyle{definition}
\newtheorem{example}{Example}[subsubsection]
\newtheorem*{remark}{Remark}
\newtheorem{theorem}{Theorem}[subsubsection]
\newtheorem{definition}{Definition}[subsubsection]
\newtheorem{corollary}{Corollary}[subsubsection]
\hypersetup{
	colorlinks=false,      % false: boxed links; true: colored links
	linkcolor=blue,        % color of internal links
	citecolor=blue,        % color of links to bibliography
	filecolor=magenta,     % color of file links
	urlcolor=blue         
}
\usepackage{titling}
\renewcommand\maketitlehooka{\null\mbox{}\vfill}
\renewcommand\maketitlehookd{\vfill\null}
\usepackage{siunitx} % units
\usepackage{verbatim} 
\newcommand{\studyTitle}{Study Guide} 
\newcommand{\class}{MATH 163: Discrete Mathematics 1 Fall 2022}
\newcommand{\professor}{Dr. Petrescu}
\newcommand{\name}{Denny Cao}
\newcommand{\final}{Monday, December 12, 2022}
\pagestyle{fancy}
\fancyhf{}% clears all header and footer fields
\fancyfoot[C]{--~\thepage~--}
\renewcommand*{\headrulewidth}{0.4pt}
\renewcommand*{\footrulewidth}{0pt}
\lhead{\name}
\chead{\leftmark}
\rhead{\professor}


\fancypagestyle{plain}{%
  \fancyhf{}% clears all header and footer fields
  \fancyfoot[C]{--~\thepage~--}%
  \renewcommand*{\headrulewidth}{0pt}%
  \renewcommand*{\footrulewidth}{0pt}%
}

% Shortcuts
\newcommand{\xor}{\oplus} % exclusive or
\newcommand{\true}{\textbf{T}} % true
\newcommand{\false}{\textbf{F}} % false
\newcommand{\lra}{\leftrightarrow} % iff

\newcommand{\powset}{\mathcal{P}} % power set

\newcommand{\comp}{\circ} % composition
\DeclarePairedDelimiter\ceil{\lceil}{\rceil} % ceil function
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor} % floor function
\DeclarePairedDelimiter\abs{\lvert}{\rvert} % absolute value

\DeclarePairedDelimiter\paren{(}{)} % parenthesis

\newcommand{\df}{\displaystyle\frac} % displaystyle fraction
\newcommand{\qeq}{\overset{?}{=}} % questionable equality

\newcommand{\Mod}[1]{\;\mathrm{mod}\; #1} % modulo operator

% Sets
\DeclarePairedDelimiter\set{\{}{\}}
\newcommand{\unite}{\cup}
\newcommand{\inter}{\cap}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\realspos}{\mathbb{R}^+} % real numbers: textbook is Z^+
\newcommand{\ints}{\mathbb{Z}}
\newcommand{\posints}{\mathbb{Z}^+}
\newcommand{\nats}{\mathbb{N}} % textbook is Z^+ and 0
\newcommand{\rats}{\mathbb{Q}}
\newcommand{\comps}{\mathbb{C}}

% Counting
\newcommand\perm[2][^n]{\prescript{#1\mkern-2.5mu}{}P_{#2}}
\newcommand\comb[2][^n]{\prescript{#1\mkern-0.5mu}{}C_{#2}}

\setlength\parindent{0pt}

% Sign Charts
\newdimen\tcolw \tcolw=2.5em % the column width
\edef\ecatcode{\catcode`&=\the\catcode`&\relax}\catcode`&=4
\def\sgchart#1#2{\vbox{\offinterlineskip\halign{\hfil##\quad&##\hfil\crcr\sgchartA#2,:,%
   \omit\sgchartR&\kern.2pt\sgchartS{.5\tcolw}\relax\sgchartE#1,\relax,%
   \sgchartS{.5\tcolw}\relax\cr
   \noalign{\kern2pt}&\def~{}\kern.5\tcolw\sgchartD#1,\relax,\cr}}}
\def\sgchartA#1:#2,{\cr\ifx,#1,\else $#1$&\sgchartB#2{}\expandafter\sgchartA\fi}
\def\sgchartB#1{\hbox to\tcolw{\hss$#1$\hss}\sgchartC}
\def\sgchartC#1{\ifx,#1,\else
   \strut\vrule\kern-.4pt\hbox to\tcolw{\hss$#1$\hss}\expandafter\sgchartC\fi}
\def\sgchartD#1#2,{\ifx\relax#1\else\hbox to\tcolw{\hss$#1#2$\hss}\expandafter\sgchartD\fi}
\def\sgchartE#1#2,{\ifx\relax#1\else
    \ifx~#1\sgchartS\tcolw\circ \else\sgchartS\tcolw\bullet\fi \expandafter\sgchartE\fi}
\def\sgchartR{\leaders\vrule height2.8pt depth-2.4pt\hfil}
\def\sgchartS#1#2{\hbox to#1{\kern-.2pt\sgchartR \ifx\relax#2\else
   \kern-.7pt$#2$\kern-.7pt\sgchartR\fi\kern-.2pt}}
\ecatcode
%++++++++++++++++++++++++++++++++++++++++
\title{
    \vspace{2in}
    \textmd{\textbf{\studyTitle}}
    \normalsize\vspace{0.1in}\\
    \vspace{0.1in}\large{\text{\class}} \\
    \vspace{0.1in}\text{\professor}\\
    \vspace{0.1in}\large\text{Final: \text{\final}}\\
    \vspace{3in}
}

\author{\name}
\date{\today}

\begin{document}
    \maketitle
    \thispagestyle{empty}
    \pagebreak
    \tableofcontents
    \pagebreak
    
    \section{Logic and Proofs}  
    \subsection{Propositional Logic}
    \stepcounter{subsubsection}
    \subsubsection{Propositions}
    \begin{definition}
        \textbf{Proposition:} A statement that is either true or false.
    \end{definition}    
    \begin{figure}[H]
        \centering
            \begin{tabular}{c|c}
                $p$ & $\neg p$ \\
                \hline
                T & F \\
                F & T
            \end{tabular}
        \caption{Truth table for \textbf{negation}}
    \end{figure}
    \begin{figure}[H]
        \centering
            \begin{tabular}{c|c|c|c|c}
                $p$ & $q$ & $p \land q$ & $p \lor q$ & $p \xor q$ \\
                \hline
                T & T & T & T & F \\
                T & F & F & T & T \\
                F & T & F & T & T \\
                F & F & F & F & F
            \end{tabular}
        \caption{Truth table for \textbf{bit operations}}
    \end{figure}
    \subsubsection{Conditional Statements}
    \begin{definition}
        \textbf{Conditional Statement:} A statement of the form $p \to q$. The conditional statement is called the \textit{hypothesis} (or \textit{antecedent} or \textit{premise}) and $q$ is called the \textit{conclusion} (or \textit{consequence}). 
    \end{definition}
    \begin{definition}
        \textbf{Converse:} The proposition $q \to p$ is the converse of the proposition $p \to q$. 
    \end{definition}
    \begin{figure}[H]
        \centering
            \begin{tabular}{c|c|c}
                $p$ & $q$ & $q \to p$ \\
                \hline
                T & T & T \\
                T & F & T \\
                F & T & F \\
                F & F & T 
            \end{tabular}   
        \caption{Truth Table for converse of implication of two propositions $p$ and $q$}
    \end{figure}
    \begin{definition}
        \textbf{Contrapositive:} The proposition $\neg q \to \neg p$ is the contrapositive of the proposition $p \to q$.  
    \end{definition}
    \begin{itemize}
        \item Same truth value as $p \to q$
    \end{itemize}
    \begin{figure}[H]
        \centering
            \begin{tabular}{c|c|c|c|c}
                $p$ & $q$ & $\neg{p}$ & $\neg{q}$ & $\neg q \to \neg p$ \\
                \hline
                T & T & F & F & T \\
                T & F & F & T & F \\
                F & T & T & F & T \\
                F & F & T & T & T
            \end{tabular}   
        \caption{Truth Table for contrapositive of implication of two propositions $p$ and $q$}
    \end{figure}
    \begin{definition}
        \textbf{Inverse:} The proposition $\neg p \to \neg q$ is the inverse of the proposition $p \to q$.    
    \end{definition}
    \begin{figure}[H]
        \centering
            \begin{tabular}{c|c|c|c|c}
                $p$ & $q$ & $\neg{p}$ & $\neg{q}$ & $\neg p \to \neg q$ \\
                \hline
                T & T & F & F & T \\
                T & F & F & T & T \\
                F & T & T & F & F \\
                F & F & T & T & T
            \end{tabular}    
        \caption{Truth Table for inverse of implication of two propositions $p$ and $q$}
    \end{figure}
    \stepcounter{subsubsection}
    \subsubsection{Precedence of Logical Operators}
    \begin{figure}[H]
        \centering
        \begin{tabular}{|c|c|}
            \hline
            Operator & Precedence \\
            \hline
            $\neg$ & 1 \\
            $\land$ & 2 \\
            $\lor$ & 3 \\
            $\to$ & 4 \\
            $\lra$ & 5 \\
            \hline        
        \end{tabular}
        \caption{Precedence of Logical Operators}
    \end{figure}
    \stepcounter{subsection}
    \subsection{Propositional Equivalences}
    \subsubsection{Introduction}
    \begin{definition}
        \textbf{Tautology:} A compound proposition that is always true.
    \end{definition}
    \begin{definition}
        \textbf{Contradiction:} A compound proposition that is always false.  
    \end{definition}
    \begin{definition}
        \textbf{Contingency:} A compound proposition that is neither a tautology nor a contradiction. 
    \end{definition}
    \begin{figure}[H]
        \centering
        \begin{tabular}{c|c|c|c}
            $p$ & $\neg q$ & $p \lor \neg q$ & $p \land \neg q$ \\
            \hline
            T & T & T & F \\
            T & F & T & F \\
        \end{tabular}
        \caption{Truth Table of an example of a Tautology and Contradiction}
    \end{figure}
    \subsubsection{Logical Equivalences}
    \begin{definition}
        Two propositions are \textbf{logically equivalent} if $p \lra q$ is a tautology.    
    \end{definition}
    The following are important logical equivalences:
    \begin{figure}[H]
        \centering
        \begin{tabular}{|c|}
            \hline
            De Morgan's Laws \\
            \hline
            \begin{tabular}{c}
                $\neg(p \land q) \lra \neg p \lor \neg q$ \\
                $\neg(p \lor q) \lra \neg p \land \neg q$ \\
            \end{tabular} \\
            \hline
        \end{tabular}
    \end{figure}
    \begin{figure}[H]
        \centering
        \begin{tabular}{|c|}
            \hline
            Conditional-Disjunction Equivalence \\
            \hline
            \begin{tabular}{c}
                $p \to q \lra \neg p \lor q$ \\
            \end{tabular} \\
            \hline
        \end{tabular}
    \end{figure}    

    Here are some other logical equivalences:
    \begin{figure}[H]
        \centering
        {\setlength{\tabcolsep}{2em}
        \begin{tabular}{|c|c|}
            \hline
            \multicolumn{2}{|c|}{} \\
            \multicolumn{2}{|c|}{Logical Equivalences} \\
            \multicolumn{2}{|c|}{} \\
            \hline
            Equivalence & Name \\
            \hline
            $p \land \true \equiv \true$ & Identity Laws \\
            $p \land \false \equiv \false$ &  \\
            \hline
            $p \lor \true \equiv \true$ & Domination Laws \\
            $p \lor \false \equiv \false$ &  \\
            \hline
            $p \lor p \equiv p$ & Idempotent Laws \\
            $p \land p \equiv p$ &  \\
            \hline
            $\neg(\neg p) \equiv p$ & Double Negation Law \\
            \hline
            $p \lor q \equiv q \lor p $ & Commutative Laws \\
            $p \land q \equiv q \land p$ &  \\
            \hline
            $(p \lor q) \lor r \equiv p \lor (q \lor r)$ & Associative Laws \\
            $(p \land q) \land r \equiv p \land (q \land r)$ &  \\
            \hline
            $p \lor (q \land r) \equiv (p \lor q) \land (p \lor r)$ & Distributive Laws \\
            $p \land (q \lor r) \equiv (p \land q) \lor (p \land r)$ &  \\
            \hline
            $\neg(p \land q) \equiv \neg p \lor \neg q$ & De Morgan's Laws \\
            $\neg(p \lor q) \equiv \neg p \land \neg q$ &  \\
            \hline
            $p \lor (p \land q) \equiv p$ & Absorption Laws \\
            $p \land (p \lor q) \equiv p$ &  \\
            \hline
            $p \lor \neg p \equiv \true$ & Negation Laws \\
            $p \land \neg p \equiv \false$ &  \\
            \hline
        \end{tabular}}
    \end{figure}
    
    \begin{figure}[H]
        \centering
        {\setlength{\tabcolsep}{2em}
        \begin{tabular}{|c|}
            \hline
            \\
            Logical Equivalences Involving Conditional Statements \\
            \\
            \hline
            $p \to q \equiv \neg p \lor q$ \\
            $p \to q \equiv \neg q \to \neg p$ \\
            $p \lor q \equiv \neg p \to q$ \\
            $p \land q \equiv \neg (\neg p \lor \neg q) \equiv \neg (p \to \neg q)$ \\
            $\neg(p \to q) \equiv p \land \neg q$ \\
            $(p \to q) \land (p \to r) \equiv p \to (q \land r) $ \\
            $(p \to r) \land (q \to r) \equiv (p \lor q) \to r$ \\
            $(p \to q) \lor (p \to r) \equiv p \to (q \lor r)$ \\
            $(p \to r) \lor (q \to r) \equiv (p \land q) \to r$ \\
            \hline
        \end{tabular}}
    \end{figure}
    \begin{figure}[H]
        \centering
        {\setlength{\tabcolsep}{2em}
        \begin{tabular}{|c|}
            \hline
            \\
            Logical Equivalences Involving Biconditonal Statements \\
            \\
            \hline
            $p \lra q \equiv (p \to q) \land (q \to p)$ \\
            $p \lra q \equiv \neg p \lra \neg q$ \\
            $p \lra q \equiv (p \land q) \lor (\neg p \land \neg q)$ \\
            $\neg(p \lra q) \equiv p \lra \neg q$ \\
            \hline
        \end{tabular}}
    \end{figure}
    \begin{equation*}
        \bigvee_{i=1}^n p_i = p_1 \lor p_2 \lor \cdots \lor p_n
    \end{equation*}
    \begin{equation*}
        \bigwedge_{i=1}^n p_i = p_1 \land p_2 \land \cdots \land p_n
    \end{equation*}
    By De Morgan's laws, it follows that:
    \stepcounter{subsubsection}
    \stepcounter{subsubsection}
    \begin{equation*}
        \neg \bigvee_{i=1}^n p_i = \bigwedge_{i=1}^n \neg p_i
    \end{equation*}
    \subsubsection{Satisfiability}
    \begin{definition}
        A compound proposition is \textbf{satisfiable} if there is an assignment of truth values to its variables that makes it true (When it is a tautology or a contigency). 
    \end{definition}
    \begin{definition}
        A compound proposition is \textbf{unsatisfiable} if there is no assignment of truth values to its variables that makes it true (When it is a contradiction). To prove this, we can prove that the negation is a tautology.
    \end{definition}
    \subsection{Predicates and Quantifiers}
    \stepcounter{subsubsection}
    \subsubsection{Predicates}
    \begin{definition}
        A \textbf{statement} contains 2 parts: a \textbf{subject} and a \textbf{predicate}.
        \begin{itemize}
            \item In the statement, $x$ is greater than 3, $x$ is the subject and greater than 3 is the predicate.
            \item The statement $P(x)$ is said to be the value of the \textbf{propositional function} $P$ at $x$.
        \end{itemize}
    \end{definition}
    \subsubsection{Quantifiers}
    \begin{definition}
        \textbf{Universal Quantifier}: $\forall x P(x)$. $P(x)$ for all values of $x$ in the domain.
        \begin{itemize}
            \item An element for which $P(x)$ is false is called a \textbf{counterexample}.
        \end{itemize}   
    \end{definition}
    \begin{definition}
        \textbf{Existential Quantifier}: $\exists x P(x)$. There exists an element $x$ in the domain such that $P(x)$ is true.    
    \end{definition}
    \begin{definition}
        \textbf{Uniqueness Quantifier}: $\exists! x P(x)$. There exists exactly one element $x$ in the domain such that $P(x)$ is true.    
    \end{definition}
    
    \textit{A way to think about determining the truth value of quantifiers is to think about looping. To determine if $\forall x P(x)$ is true, we loop through all the elements in the domain and check if $P(x)$ is true for all of them. To determine if $\exists x P(x)$ is true, we loop through all the elements in the domain and check if $P(x)$ is true for at least one of them.}
    \subsubsection{Quantifiers Over Finite Domains}
    When domain is finite, we can express statements using propositional logic:
    \begin{equation*}
        \forall x P(x) \equiv \bigwedge_{i=1}^{n} P(x)
    \end{equation*}
    \begin{equation*}
        \exists x P(x) \equiv \bigvee_{i=1}^{n} P(x)
    \end{equation*}
    \stepcounter{subsubsection}
    \subsubsection{Precedence of Quantifiers}
    $\forall x$ and $\exists x$ have higher precedence than all logical operators from propositional calculus. For instance, $\forall P(x) \lor Q(x) \equiv (\forall P(x)) \lor Q(x)$.
    \stepcounter{subsubsection}
    \subsubsection{Negating Quantified Expressions}
    \begin{figure}[H]
        \begin{align*}
            \neg \forall x P(x) &\equiv \exists x \neg P(x) \\
            \neg \exists x P(x) &\equiv \forall x \neg P(x)
        \end{align*}
        \caption{De Morgan's Laws for Quantifiers}
    \end{figure}
    \subsection{Nested Quantifiers}
    \begin{figure}[H]
        \centering
        \begin{tabular}{|c|p{12em}|p{12em}|}
            \hline
            Statement & When True & When False \\
            \hline
            $\forall x \forall y P(x,y)$ & $P(x,y)$ is true for all values of $x$ and $y$ & $\exists x \exists y \neg P(x,y)$ \\
            \hline
            $\forall x \exists y P(x,y)$ & For every $x$ there is a $y$ such that $P(x,y)$ is true & $\exists x \forall y \neg P(x,y)$ \\
            \hline
            $\exists x \forall y P(x,y)$ & There is an $x$ such that $P(x,y)$ is true for all values of $y$ & $\forall x \exists y \neg P(x,y)$ \\
            \hline
            $\exists x \exists y P(x,y)$ & There is an $x$ and a $y$ such that $P(x,y)$ is true & $\forall x \forall y \neg P(x,y)$ \\
            \hline
        \end{tabular}
        \caption{Quantifications of Two Variables}
    \end{figure}
    \subsection{Rules of Inference}
    \begin{figure}[H]
        \centering
        \begin{tabular}{|l|c|c|}
            \hline
            Rule of Inference & Tautology & Name \\
            \hline
            $\begin{array}{rl}
                & p \\
                & p \to q \\
                \cline{2-2}
                \therefore & q
            \end{array}$ & $(p \land (p \to q)) \to q$ & Modus Ponens \\
            \hline
            $\begin{array}{rl}
                & \neg q \\
                & p \to q \\
                \cline{2-2}
                \therefore & q 
            \end{array}$ & $(\neg q \land (p \to q)) \to \neg p$ & Modus Tollens \\
            \hline
            $\begin{array}{rl}
                & p \to q \\
                & q \to r \\
                \cline{2-2}
                \therefore & p \to r
            \end{array}$ & $((p \to q) \land (q \to r)) \to (p \to r)$ & Hypothetical Syllogism \\
            \hline
            $\begin{array}{rl}
                & p \lor q \\
                & \neg p \\
                \cline{2-2}
                \therefore & q
            \end{array}$ & $((p \lor q) \land \neg p) \to q$ & Disjunctive Syllogism \\
            \hline
            $\begin{array}{rl}
                & p \\
                \cline{2-2}
                \therefore & p \lor q
            \end{array}$ & $p \to (p \lor q)$ & Addition \\
            \hline
            $\begin{array}{rl}
                & p \land q \\
                \cline{2-2}
                \therefore & p
            \end{array}$ & $(p \land q) \to p$ & Simplification \\
            \hline
            $\begin{array}{rl}
                & p \\
                & q \\
                \cline{2-2}
                \therefore & p \land q
            \end{array}$ & $((p) \land (q)) \to (p \land q)$ & Conjunction \\
            \hline
            $\begin{array}{rl}
                & p \lor q \\
                & \neg p \lor r \\
                \cline{2-2}
                \therefore & q \lor r
            \end{array}$ & $((p \lor q) \land (\neg p \lor r)) \to (q \lor r)$ & Resolution \\
            \hline
        \end{tabular}
        \caption{Rules of Inference for Propositional Logic}
    \end{figure}
    Note: Resolution is saying, regardless of what $p$ is, $q$ or $r$ is true.
    \begin{figure}[H]
        \centering
        \begin{tabular}{|l|c|}
            \hline
            Rule of Inference & Name \\
            \hline
            $\begin{array}{rl}
                & \forall x P(x) \\
                \cline{2-2}
                \therefore & P(c)
            \end{array}$ & Universal Instantiation \\
            \hline
            $\begin{array}{rl}
                & P(c) \text{ for an arbitrary } c \\
                \cline{2-2}
                \therefore & \forall x P(x)
            \end{array}$ & Universal Generalization \\
            \hline
            $\begin{array}{rl}
                & \exists x P(x) \\
                \cline{2-2}
                \therefore & P(c) \text{ for some element } c
            \end{array}$ & Existential Instantiation \\
            \hline
            $\begin{array}{rl}
                & P(c) \text{ for some element } c \\
                \cline{2-2}
                \therefore & \exists x P(x)
            \end{array}$ & Existential Generalization \\
            \hline
        \end{tabular}
        \caption{Rules of Inference for Quantified Statements}
    \end{figure}
    \textbf{Universal Modus Ponens:} The usage of universal instantiation and modus ponens together.
    \begin{center}
        $\begin{array}{rl}
            & \forall x (P(x) \to Q(x)) \\
            & P(a) \text{, where } a \text{ is a particular element in the domain} \\
            \cline{2-2}
            \therefore & Q(a)
        \end{array}$
    \end{center}
    \subsection{Introduction to Proofs}
    Prove $\forall x(P(x) \to Q(x))$ by showing that $P(c) \to Q(c)$ is true, where $c$ is an arbitrary element of the domain, and then apply universal generalization.
    \stepcounter{subsubsection}
    \stepcounter{subsubsection}
    \stepcounter{subsubsection}
    \stepcounter{subsubsection}
    \subsubsection{Direct Proofs}
    Show $p \to q$ by first assuming $p$ is true and then showing that $q$ is true using the rules of inference.
    
    \begin{definition}
        The integer $n$ is \textbf{even} if $\exists k \in \ints \mid n = 2k$.
    \end{definition}
    \begin{definition}
        The integer $n$ is \textbf{odd} if $\exists k \in \ints \mid n = 2k + 1$.   
    \end{definition}
    \begin{definition}
        Two integers have the same \textbf{parity} if they are both even or both odd. They have \textbf{opposite parity} if one is even and the other is odd.     
    \end{definition}
    \subsubsection{Proof by Contraposition}
    \begin{definition}
        An \textbf{indirect proof} is a proof that does not start with the premise and ends with the conclusion. One type is \textbf{proof by contraposition}. This is a proof that shows $p \to q$ by showing $\neg q \to \neg p$.   
    \end{definition}
    \subsubsection{Proof by Contradiction}
    Another type of indirect proof is \textbf{proof by contradiction}. 
    We can prove $p$ is true by showing that $\neg p \to (r \land \neg r)$. Assume the negation of $p$ is true, and then show that $r$ and $\neg r$ are both true. This is a contradiction, so $p$ must be true.
    \\

    Important example of proof by contradiction: Prove that $\sqrt{2}$ is irrational.
    \begin{proof} By contradiction. Let $p$ be the proposition that $\sqrt{2}$ is irrational. Assum $\neg p$ is true, that is, assume $\sqrt{2}$ is rational. By definition of rational numbers, there exist integers $a$ and $b$ such that $\sqrt{2} = \frac{a}{b}$, where $\frac{a}{b}$ is in simplest terms. Then, we have:
    \begin{align*}
        \sqrt{2} &= \frac{a}{b} \\
               2 &= \frac{a^2}{b^2} \\
            2b^2 &= a^2 \\
        \intertext{Since $a^2$ is a multiple of 2, $a^2$ is even. Therefore, $a$ is even, and $a = 2k$ for some integer $k$.}
           2b^2 &= 4k^2 \\
            b^2 &= 2k^2 \\
        \intertext{Since $b^2$ is a multiple of 2, $b^2$ is even. Therefore, $b$ is even, and $b = 2l$ for some integer $l$.}
        \sqrt{2} &= \frac{2k}{2l}
    \end{align*}
    Since both $a$ and $b$ are even, we can divide both the numerator and denominator by 2. Because our assumption of $\neg p$ leads to the contradiction that 2 divides both $a$ and $b$ and 2 does not divide both $a$ and $b$, $\neg p$ is false. Therefore, $p$ is true.
    \end{proof}
    \subsection{Proof Methods and Strategy}
    \stepcounter{subsubsection}
    \subsubsection{Exhaustive Proof and Proof by Cases}
    \textbf{Exhaustive Proof}: Prove that $p \to q$ by showing:
    \begin{equation*}
        \bigvee_{i=1}^n p_i \to q
    \end{equation*}
    \textbf{Proof by Cases}: Prove that $p \to q$ by breaking $p$ into cases and showing that $q$ is true in each case.
    \section{Basic Structures}
    \subsection{Sets}
    \subsubsection{Introduction}
    \begin{definition}
        A \textbf{set} is an unordered collection of distinct objects called \textbf{elements} or \textbf{members} of the set. A set is said to \textbf{contain} its elements. We write $a \in A$ to denote that $a$ is an element of the set $A$. The notation $a \notin A$ denotes that $a$ is not an element of the set $A$.   
    \end{definition}

    Sets of types of numbers:
    \begin{itemize}
        \item Natural Numbers: $\nats = \{0, 1, 2, 3, \dots\} = \set*{\posints \unite 0}$
        \item Integers: $\ints = \{..., -2, -1, 0, 1, 2, \dots\}$
        \item Positive Integers: $\ints^+ = \{1, 2, 3, \dots\}$
        \item Rational Numbers: $\rats = \set*{\df{a}{b} \mid a, b \in \ints \text{ and } b \neq 0}$
        \item Real Numbers: $\reals$
        \item Positive Real Numbers: $\reals^+$
        \item Complex Numbers: $\comps$
    \end{itemize}

    \begin{definition}
        \textbf{Equality of Sets}:
        \begin{equation*}
            A=B \lra \forall x (x \in A \lra x \in B) \lra A \subseteq B \land B \subseteq A   
        \end{equation*}
    \end{definition}

    \begin{definition}
        \textbf{Empty Set}: $\emptyset = \set*{}$
    \end{definition}
    \stepcounter{subsubsection}
    \subsubsection{Subsets}
    \begin{definition}
        \textbf{Subset}:
        \begin{equation*}
            A \subseteq B \lra \forall x (x \in A \lra x \in B) \lra B \supseteq A
        \end{equation*}
        To show that $A \not\subseteq B$, show $\exists x (x \in A \land x \not\in B)$.
    \end{definition}

    \begin{theorem}
        For every set $S$, $\emptyset \subseteq S$ and $S \subseteq S$.
    \end{theorem}
    \subsubsection{Size of a Set}
    \begin{definition}
        Let $S$ be a set. If there are exactly $n$ distinct elements in $S$, where $n$ is a nonnegative integer, we say that $S$ is a \textbf{finite set} and that $n$ is the \textbf{cardinality} of $S$, denoted by $|S|$.
        \begin{itemize}
            \item Note: Theorem 2.1.3.1!
        \end{itemize}
    \end{definition}
    \subsubsection{Power Sets}
    \begin{definition}
        Let $S$ be a set. The \textbf{power set} of $S$, denoted by $\powset(S)$, is the set of all subsets of $S$.
    \end{definition}
    \begin{theorem} Cardinality of a power set
        \begin{equation*}
            |\powset(S)| = 2^{|S|}
        \end{equation*}
    \end{theorem}
    \subsubsection{Cartesian Products}
    \begin{definition}
        Let $A$ and $B$ be sets. The \textbf{Cartesian product} of $A$ and $B$, denoted by $A \times B$, is the set of all ordered pairs $(a,b)$ where $a \in A$ and $b \in B$. Hence:
        \begin{equation*}
            A \times B = \{(a,b) \mid a \in A \land b \in B\}    
        \end{equation*}
    \end{definition}
    \subsection{Set Operations}
    \subsubsection{Introduction}
    \begin{definition}
        Let $A$ and $B$ be sets. The \textbf{union} of the sets $A$ and $B$, denoted $A \unite B$, is the set that contains those elements that are in either $A$ or $B$ or both. Hence:
        \begin{equation*}
            A \unite B = \{x \mid x \in A \lor x \in B\}
        \end{equation*}
    \end{definition}
    \begin{definition}
        Let $A$ and $B$ be sets. The \textbf{intersection} of the sets $A$ and $B$, denoted $A \inter B$, is the set that contains those elements in both $A$ and $B$. Hence:
        \begin{equation*}
            A \inter B = \{x \mid x \in A \land x \in B\}
        \end{equation*}
    \end{definition}
    \begin{definition}
        Two sets are called \textbf{disjoint} if their intersection is the emptyset.
    \end{definition}
    \begin{definition}
        Let $A$ and $B$ be sets. The \textbf{difference} of the sets $A$ and $B$, denoted $A - B$, is the set that contains those elements in $A$ but not in $B$. It is also called the \textbf{complement of $B$ with respect to $A$}. Hence:
        \begin{equation*}
            A - B = \{x \mid x \in A \land x \not\in B\}
        \end{equation*}
    \end{definition}
    \begin{definition}
        Let $U$ be the universal set. The \textbf{complement} of a set $A$, denoted $\overline{A}$, is the set $U - A$. Hence:
        \begin{equation*}
            \overline{A} = \{x \mid x \in U \land x \not\in A\}
        \end{equation*}
    \end{definition}
    \begin{definition}
        Let $A$ and $B$ be sets. The \textbf{symmetric difference} of $A$ and $B$ is the set of elements that are in either $A$ or $B$ but not in both. It is denoted by $A \xor B$. Hence:
        \begin{equation*}
            A \xor B = (A \unite B) - (A \inter B)
        \end{equation*} 
    \end{definition}
    \subsubsection{Set Identities}
    \begin{figure}[H]
        \centering
        {\renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|l|c|}
            \hline
            Identity & Name \\
            \hline
            $A \inter U = A$ & Identity Laws \\
            $A \unite \emptyset = A$ & \\
            \hline
            $A \unite U = U$ & Domination Laws \\
            $A \inter \emptyset = \emptyset$ & \\
            \hline
            $A \unite A = A$ & Idempotent Laws \\
            $A \inter A = A$ & \\
            \hline
            $\overline{(\overline{A})} = A$ & Complementation Law \\
            \hline
            $A \unite B = B \unite A$ & Commutative Laws \\
            $A \inter B = B \inter A$ & \\
            \hline
            $A \unite (B \unite C) = (A \unite B) \unite C$ & Associative Laws \\
            $A \inter (B \inter C) = (A \inter B) \inter C$ & \\
            \hline
            $A \unite (B \inter C) = (A \unite B) \inter (A \unite C)$ & Distributive Laws \\
            $A \inter (B \unite C) = (A \inter B) \unite (A \inter C)$ & \\
            \hline
            $\overline{A \inter B} = \overline{A} \unite \overline{B}$ & De Morgan's Laws \\
            $\overline{A \unite B} = \overline{A} \inter \overline{B}$ & \\
            \hline
            $A \unite (A \inter B) = A$ & Absorption Laws \\
            $A \inter (A \unite B) = A$ & \\
            \hline
            $A \unite \overline{A} = U$ & Complement Laws \\
            $A \inter \overline{A} = \emptyset$ & \\
            \hline
        \end{tabular}}
        \caption{Set Identities}
    \end{figure}
    There are 3 ways to prove that two sets are equal:
    \begin{enumerate}
        \item Showing that they are subsets of each other. (Definition 2.2)
        \item Membership tables.
        \item Set identities.
    \end{enumerate}
    A \textbf{membership table} considers each combination of the atomic sets (the original sets used to produce the sets on each side) that an element can belong to and verify that elements in the same combinations of sets belong to both the sets in the identity. Use a 1 to indicate that an element belongs to a set and a 0 to indicate that it does not. For example, consider the following identity:
    \begin{equation*}
        A \unite (A \inter B) = A
    \end{equation*}
    We can construct a membership table for this identity as follows:
    \begin{center}
        \begin{tabular}{|c|c|c|}
            \hline
            $A$ & $B$ & $A \unite (A \inter B)$ \\
            \hline
            1 & 1 & 1 \\
            1 & 0 & 1 \\
            0 & 1 & 0 \\
            0 & 0 & 0 \\
            \hline
        \end{tabular}
    \end{center}
    Since the columns are the same, we can conclude that the sets are equal.
    \subsubsection{Generalized Unions and Intersections}
    \begin{definition}
        The \textbf{union} of a collection of sets is the set that contains those elements that are members of at least one set in the collection. It is denoted by:
        \begin{equation*}
            A_1 \unite A_2 \unite \cdots A_n = \bigcup_{i=1}^{n} A_i
        \end{equation*}
    \end{definition}
    \begin{definition}
        The \textbf{intersection} of a collection of sets is the set that contains those elements that are members of all sets in the collection. It is denoted by:
        \begin{equation*}
            A_1 \inter A_2 \inter \cdots A_n = \bigcap_{i=1}^{n} A_i
        \end{equation*}
    \end{definition}
    \subsection{Functions}
    \subsubsection{Introduction}
    \begin{definition}
        Let $A$ and $B$ be nonempty sets. A \textbf{function} $f$ from $A$ to $B$ is an assignment of exactly one element of $B$ to each element of $A$. We write $f(a) = b$ if $b$ is the unique element of $B$ assigned by the function $f$ to the element $a$ of $A$. If $f$ is a function from $A$ to $B$, we write $f: A \to B$.
        \begin{itemize}
            \item Functions are sometimes also called \textbf{mappings} or \textbf{transformations}
        \end{itemize}
    \end{definition}
    \begin{definition}
        Let $f: A \to B$ be a function. $A$ is the \textbf{domain} of $f$ and $B$ is the \textbf{codomain} of $f$. If $f(a) = b$, we say that $b$ is the \textbf{image} of $a$ and $a$ is the \textbf{preimage} of $b$. The \textbf{range}, or \textbf{image} of $f$ is the set of all images of elements of $A$. Also, if $f$ is a function from $A$ to $B$, we say that $f$ \textbf{maps} $A$ to $B$.
        \begin{itemize}
            \item Codomain is set of possible values of the function and range is the set of all elements of the codomain that are achieved as the value of $f$ for at least one element of the domain.
            \item Two functions are \textbf{equal} when they have the same domain, same codomain, and map each each element of their common domain to the same element in their common codomain.
        \end{itemize}
    \end{definition}
    \begin{definition}
        Let $f_1$ and $f_2$ be functions from $A$ to $B$. Then $f_1 + f_2$ and $f_1f_2$ are also functions from $A$ to $B$ defined $\forall x \in A$ by:
        \begin{align*}
            (f_1 + f_2)(x) &= f_1(x) + f_2(x) \\
               (f_1f_2)(x) &= f_1(x)f_2(x)
        \end{align*}
    \end{definition}
    \begin{definition}
        Let $f$ be a function from $A$ to $B$ and let $S \subseteq A$. The \textbf{image} of $S$ under the function $f$ is the subset of $B$ that consists of the images of the elements of $S$. We denote the image of $S$ by $f(S)$, so:
        \begin{equation*}
            f(S) = \set*{t \mid \exists s \in S (t = f(s))} = \set*{f(s) \mid s \in S}
        \end{equation*}
    \end{definition}
    \subsubsection{One-to-One and Onto Functions}
    \begin{definition}
        A function $f$ with domain $A$ is \textbf{one-to-one} if and only if: 
        \begin{equation*}
            \forall a \forall b (a,b \in A \land (f(a) = f(b) \to a = b))
        \end{equation*}
        \begin{itemize}
            \item A function $f$ is one-to-one if and only if $f(a) \neq f(b)$ whenever $a \neq b$. This is obtained by taking the contrapositve of the implication in the definition.
        \end{itemize}
    \end{definition}
    \begin{definition}
        A function $f$ whose domain $A$ and codomain $B$ are subsets of the set of real numbers is called \textbf{increasing} if $f(x) \leq f(y)$ whenever $x < y$ and $x,y \in A$. Hence:
        \begin{equation*}
            \forall x \forall y (x,y \in A \land x < y \to f(x) \leq f(y))
        \end{equation*}
    \end{definition}
    \begin{definition}
        A function $f$ whose domain $A$ and codomain $B$ are subsets of the set of real numbers is called \textbf{strictly increasing} if $f(x) < f(y)$ whenever $x < y$ and $x,y \in A$. Hence:
        \begin{equation*}
            \forall x \forall y (x,y \in A \land x < y \to f(x) < f(y))
        \end{equation*}
    \end{definition}
    \begin{definition}
        A function $f$ whose domain $A$ and codomain $B$ are subsets of the set of real numbers is called \textbf{decreasing} if $f(x) \geq f(y)$ whenever $x < y$ and $x,y \in A$. Hence:
        \begin{equation*}
            \forall x \forall y (x,y \in A \land x < y \to f(x) \geq f(y))
        \end{equation*}
    \end{definition}
    \begin{definition}
        A function $f$ whose domain $A$ and codomain $B$ are subsets of the set of real numbers is called \textbf{strictly decreasing} if $f(x) > f(y)$ whenever $x < y$ and $x,y \in A$. Hence:
        \begin{equation*}
            \forall x \forall y (x,y \in A \land x < y \to f(x) > f(y))
        \end{equation*}
    \end{definition}
    \begin{definition}
        A function $f$ from $A$ to $B$ is \textbf{onto}, or a \textbf{surjection}, if and only if for every element $y \in B$ there exists an element $x \in A$ such that $f(x) = y$. Hence:
        \begin{equation*}
            \forall y \exists x (f(x) = y)
        \end{equation*}
        where the domain for $x$ is $A$ and the domain of $y$ is $B$.
        \begin{itemize}
            \item $f$ is \textbf{surjective} if it is onto.
        \end{itemize}
    \end{definition}
    \begin{definition}
        The function $f$ is a \textbf{one-to-one correspondence} if it is both one-to-one and onto. 
        \begin{itemize}
            \item Such a function is \textbf{bijective}
        \end{itemize}
        \label{def:one-to-one-correspondence}
    \end{definition}
    \begin{figure}[H]
        \centering
        {\renewcommand{\arraystretch}{1.5}
        \begin{tabular}{|l p{25em}|}
            \hline
            \multicolumn{2}{|l|}{Suppose that $f: A \to B$.} \\
            \hline
            Show $f$ is injective: & Show that if $f(x) = f(y)$ for arbitrary $x,y \in A$, then $x = y$ \\
            Show $f$ is not injective: & Find particular elements, $x,y \in A$ such that $x \neq y$ and $f(x)=f(y)$. \\
            Show $f$ is surjective: & Consider an arbitrary element $y \in B$ and find an element $x \in A$ such that $f(x) = y$. \\
            Show $f$ is not surjective: & Find a particular $y \in B$ such that $f(x) \neq y$ for all $x \in A$. \\
            Show $f$ is bijective: & Show that $f$ is both injective and surjective. \\
            \hline
        \end{tabular}}
    \end{figure}
    \subsubsection{Inverse Functions and Composite Functions}
    \begin{definition}
        Let $f$ be a one-to-one correspondence from the set $A$ to the set $B$. The \textbf{inverse function} of $f$ is denoted by $f^{-1}$: Hence: 
        \begin{equation*}
            f^{-1}(b) = a \text{ when } f(a) = b
        \end{equation*}
        \begin{itemize}
            \item A one-to-one correspondence $f$ is \textbf{invertible} because we can define an inverse function $f^{-1}$.
            \item A function is \textbf{invertible} if it is not a one-to-one correspondence, because the inverse of $f$ does not exist.
        \end{itemize}
    \end{definition}
    \begin{definition}
        Let $g$ be a function from the set $A$ to the set $B$ and let $f$ be a function from the set $B$ to the set $C$. The \textbf{composition} of the functions $f$ and $g$, denoted for all $a \in A$ by $f \comp g$, is the function from $A$ to $C$ defined by:
        \begin{equation*}
            (f \comp g)(a) = f(g(a))
        \end{equation*}
        \begin{itemize}
            \item $f \comp g$ assigns the element $a$ of $A$ the element assigned by $f$ to $g(a)$. 
            \item The domain of $f \comp g$ is the domain of $g$.
            \item The range of $f \comp g$ is the image of the range of $g$ with respect to $f$.
            \item The composition $f \comp g$ cannot be defined unless the range of $g$ is a subset of the domain of $f$. 
            \item \textbf{Not Commutative!} 
            \begin{equation*}
                f \comp g \neq g \comp f
            \end{equation*}
            \item When composing with inverse function, an identity function is obtained:
            \begin{equation*}
                f \comp f^{-1}(a) = f^{-1} \comp f(a) = a
            \end{equation*}
        \end{itemize}
    \end{definition}
    \stepcounter{subsubsection}
    \subsubsection{Some Important Functions}
    \begin{definition}
        The \textbf{floor function} assigns to the real number $x$ the largest integer that is less than or equal to $x$. The value of the floor function at $x$ is denoted by $\floor*{x}$. The \textbf{ceiling function} assigns to the real number $x$ the smllest integer that is greater than or equal to $x$. The value of the ceiling function at $x$ is denoted by $\ceil*{x}$.
    \end{definition}
    \begin{figure}[H]
        \centering
        {\renewcommand{\arraystretch}{1.3}
        \begin{tabular}{|c|}
            \hline
            \textbf{$n$ is an integer, $x$ is a real number} \\
            \hline
            $\floor*{x} = n \lra n \leq x < n+1$ \\
            $\ceil*{x} = n \lra n-1 < x \leq n$ \\
            $\floor*{x} = n \lra x-1 < n \leq x$ \\
            $\ceil*{x} = n \lra x \leq n < x+1$ \\
            \hline
            $x-1 < \floor*{x} \leq x \leq \ceil*{x} < x+1$ \\
            \hline
            $\floor*{-x} = -\ceil*{x}$ \\
            $\ceil*{-x} = -\floor*{x}$ \\
            \hline
            $\floor*{x+n} = \floor*{x} + n$ \\
            $\ceil*{x+n} = \ceil*{x} + n$ \\
            \hline
        \end{tabular}}
        \caption{Useful Properties of the Floor and Ceiling Functions}
    \end{figure}
    \subsection{Sequences and Summations}
    \stepcounter{subsubsection}
    \subsubsection{Sequences}
    \begin{definition}
        A \textbf{sequence} is a function from the set of integers to a set $S$. We use the notation $a_n$ to denote the image of the integer $n$. $a_n$ is called a \textbf{term} of the sequence.
    \end{definition}
    \begin{definition}
        A \textbf{geometric progression} is a sequence of the form:
        \begin{equation*}
            a, ar, ar^2, \dots, ar^n, \dots 
        \end{equation*}
        where the \textbf{initial term} $a$ and the \textbf{common ratio} $r$ are real numbers.
    \end{definition}
    \begin{definition}
        An \textbf{arithmetic progression} is a sequence of the form:
        \begin{equation*}
            a, a+d, a+2d, \dots, a+nd, \dots
        \end{equation*}
        where the \textbf{initial term} $a$ and the \textbf{common difference} $d$ are real numbers.
    \end{definition}
    \subsubsection{Recursive Relations}
    \begin{definition}
        A \textbf{recursive relation} for the sequence $\set*{a_n}$ is an equation that expresses $a_n$ in terms of one or more of the previous terms of the sequence, namely, $a_0, a_1, \dots, a_{n-1}$, for all integers $n$ with $n \geq n_0$, where $n_0$ is a nonnegative integer. A sequence is called a \textbf{solution} of a recurrence relation if its terms satisfy the recurrence relation.
    \end{definition}
    \begin{definition}
        The \textbf{Fibonacci sequence} is a sequence of integers defined by the recurrence relation:
        \begin{equation*}
            f_0 = 0, \quad f_1 = 1, \quad f_{n+2} = f_{n+1} + f_n
        \end{equation*}
    \end{definition}
    \stepcounter{subsubsection}
    \subsubsection{Summations}
    \begin{definition}
        The \textbf{sum} of a sequence $\set*{a_n}$ is the real number:
        \begin{equation*}
            \sum_{j=0}^{n} a_j = a_0 + a_1 + a_2 + \dots
        \end{equation*}
    \end{definition}
    \begin{theorem}
        If $a$ and $r$ are real numbers and $r \neq 0$, then:
        \begin{equation*}
            \sum_{j=0}^{n} ar^j = \begin{cases}
                                    \df{ar^{n+1} - a}{r-1}, & \text{if } r \neq 1 \cr a(n+1), & \text{if } r = 1
                                  \end{cases}
        \end{equation*}
    \end{theorem}
    \begin{figure}[H]
        \centering
        {\renewcommand{\arraystretch}{2}
        \begin{tabular}{|c|c|}
            \hline
            Sum & Closed Form \\
            \hline
            $\displaystyle\sum_{k=0}^{n}ar^k, r \neq 0$ & $\df{ar^{n+1}-a}{r-1}, r \neq 1$ \\
            $\displaystyle\sum_{k=1}^n k$               & $\df{n(n+1)}{2}$ \\
            $\displaystyle\sum_{k=1}^n k^2$             & $\df{n(n+1)(2n+1)}{6}$ \\
            $\displaystyle\sum_{k=1}^n k^3$             & $\df{n^2(n+1)^2}{4}$ \\
            $\displaystyle\sum_{k=0}^{\infty}x^k, \abs*{x} < 1$ & $\df{1}{1-x}$ \\
            $\displaystyle\sum_{k=1}^{\infty}kx^{k-1}, \abs*{x} < 1$ & $\df{1}{(1-x)^2}$ \\
            \hline
        \end{tabular}}
        \caption{Some Useful Summation Formulae}
    \end{figure}
    \subsection{Cardinality of Sets}
    \subsubsection{Introduction}
    \begin{definition}
        The sets $A$ and $B$ have the \textbf{same cardinality} if and only if there is a one-to-one correspondence from $A$ to $B$. When $A$ and $B$ have the same cardinality, we write $|A| = |B|$.
        \begin{itemize}
            \item For infinite sets, the definition of cardinality provides a relative measure of the size of two sets, rather than a measure of the size of one particular set. 
        \end{itemize}
    \end{definition}
    \begin{definition}
        If there is a one-to-one correspondence from $A$ to $B$, the cardinality of $A$ is less than or equal to the cardinality of $B$ and we write $|A| \leq |B|$. Moreover, when $|A| \leq |B|$ and $A$ and $B$ have different cardinality, we say that the cardinality of $A$ is less than the cardinality of $B$ and we write $|A| < |B|$.
    \end{definition}
    \begin{remark}
        Definitions 2.5.1.1 and 2.5.1.2 do not give any separate meaning to $|A|$ and $|B|$ when $A$ and $B$ are arbitrary infinite sets.
    \end{remark}
    \subsubsection{Countable Sets}
    \begin{definition}
        A set that is either finite or has the same cardinality as the set of positive integers is called \textbf{countable}. A set that is not countable is called \textbf{uncountable}. When an infinite set $S$ is countable, we denote the cardinality of $S$ by $\aleph_0$. We write $|S| = \aleph_0$ and say that $S$ has cardinality ``aleph null.''
        \begin{itemize}
            \item To prove that a set is countable, we must show that there is a one-to-one correspondence between the set and the set of positive integers (\hyperref[def:one-to-one-correspondence]{Refer to Definition 2.3.2.7})
        \end{itemize}
    \end{definition}
    The following are examples of how to prove some common sets are countable:
    \begin{example}
        Prove that $\ints$ is countable. \\
        \begin{proof}
            We can list all integers in a sequence by starting with 0 and alternating between positive and negative integers: $0, 1, -1, 2, -2, 3, -3, \dots$. Let $f$ have the domain $\ints^+$.
            \begin{equation*}
                f(n) = \begin{cases}
                            \df{n}{2}, & \text{if } n \text{ is even} \cr
                            -\df{n-1}{2}, & \text{if } n \text{ is odd}
                        \end{cases}
            \end{equation*}
            Since when $n$ is even, $f(n)$ maps to all positive integers, and when $n$ is odd, $f(n)$ maps to all negative integers and 0, the codomain of $f$ is $\ints$. Since there is a function $f$ that maps $\ints^+$ to $\ints$, we can conclude that $\ints$ is countable.
        \end{proof}
    \end{example}
    \begin{example}
        Prove that $\rats^+$ is countable.
        \begin{proof}
            Every positive rational number is the quotient $p/q$ of two positive integers. We can arrange the positive rational numbers by listing those with denominator $q=1$ in the first row, those with denominator $q=2$ in the second row, and so on:
            \begin{align*}
                \begin{tabular}{c | c c c c c c}
                      & 1           & 2           & 3           & 4           & 5           & $\cdots$ \\
                      \hline\rule{0pt}{1.2\normalbaselineskip} 
                    1 & $\frac{1}{1}$ & $\frac{2}{1}$ & $\frac{3}{1}$ & $\frac{4}{1}$ & $\frac{5}{1}$ & $\cdots$ \\[1em]
                    2 & $\frac{1}{2}$ & $\frac{2}{2}$ & $\frac{3}{2}$ & $\frac{4}{2}$ & $\frac{5}{2}$ & $\cdots$ \\[1em]
                    3 & $\frac{1}{3}$ & $\frac{2}{3}$ & $\frac{3}{3}$ & $\frac{4}{3}$ & $\frac{5}{3}$ & $\cdots$ \\[1em]
                    4 & $\frac{1}{4}$ & $\frac{2}{4}$ & $\frac{3}{4}$ & $\frac{4}{4}$ & $\frac{5}{4}$ & $\cdots$ \\[1em]
                    5 & $\frac{1}{5}$ & $\frac{2}{5}$ & $\frac{3}{5}$ & $\frac{4}{5}$ & $\frac{5}{5}$ & $\cdots$ \\[1em]
                    $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$
                \end{tabular}    
            \end{align*}
            Each rational number can be represented by the ordered pair $(i,j)$ where $i$ is the row number and $j$ is the column number. We can see by snaking a line from $\rats^{+}_{11}$ to $\rats^{+}_{21}$ to $\rats^{+}_{12}$ to $\rats^{+}_{13}$ to $\rats^{+}_{31}$ and so forth, such that there is a zigzag-ing enumeration, we can list the element of $\rats^+$ in a sequence indexed by the positive integers, and thus $\rats^+$ is countable.
        \end{proof}
    \end{example}
    \begin{remark}
        Note that the same proof can be used to show that $\rats^-$ is countable, and thus the union of $\rats^+$ and $\rats^-$ is countable. By using the ordered pair $(0,0)$, we can show that $\rats$ is countable.
    \end{remark}
    \subsubsection{Uncountable Sets}
    We can utilize the \textbf{Cantor diagonalization argument} to prove that the set of real numbers is uncountable.
    \begin{example}
        Prove that $\reals$ is uncountable. 
        \begin{proof} By contradiction. 
            Suppose $\reals$ is countable. Then, the subset of all real numbers that fall between 0 and 1 would also be countable (The subset of a countable set is countable). Under this assumption, the real numbers between 0 and  can be listed in some order, $r_1, r_2, r_3, \dots$. Let the decimal representation of these real numbers be: 
            \begin{align*}
                r_1 &= 0.d_{11}d_{12}d_{13}d_{14}\dots \\
                r_2 &= 0.d_{21}d_{22}d_{23}d_{24}\dots \\
                r_3 &= 0.d_{31}d_{32}d_{33}d_{34}\dots \\
                r_4 &= 0.d_{41}d_{42}d_{43}d_{44}\dots \\
                    &\vdotswithin{=}
            \end{align*}
            where $d_{ij} \in \set*{x \mid 0 \leq x \leq 9}$. Then, form a new real number with decimal expansion $r=0.d_1d_2d_3d_4\dots$, where the decimal digits are determined by the following rule:
            \begin{equation*}
                d_i = \begin{cases}
                            4 & \text{if } d_{ii} \neq 4 \\
                            5 & \text{if } d_{ii} = 4
                        \end{cases}
            \end{equation*}
            For instance, let $r_1 = 0.23794102\dots, r_2=0.44590138\dots, r_3=0.09118764\dots, r=4=0.80553900\dots,$ and so on. Then we have $r=0.d_1d_2d_3d_4\dots=0.4544$, where $d_1=4$ because $d_{11} \neq 4$, $d_2=5$ because $d_{21}=4$, $d_3=4$ because $d_{31} \neq 4$, and so on. \\
            
            Every real number has a unique decimal expansion. Therefore, the real number $r$ is not equal to any of $r_1,r_2,\dots$ because the decimal expansion of $r$ differs from the decimal expansion of $r_i$ in the $i$th place to the right of the decimal point, for each $i$. \\

            Because there is a real number $r$ between 0 and 1 that is not in the list, the assumption that all the real numbers between 0 and 1 could be listed must be false. Therefore, all the real numbers between 0 and 1 cannot be listed, so the set of real numbers between 0 and 1 is uncountable. Any set with an uncountable subset is uncountable. Hence, the set of real numbers is uncountable.
        \end{proof}
    \end{example}
    \begin{remark}
        What we essentially did in the proof was create a number that is not in the list. We proved that we can infinitely create new numbers, $r$ that are not in the list. 
    \end{remark}
    \begin{theorem}
        If $A$ and $B$ are countable sets, then $A \unite B$ is also countable.
        \begin{itemize}
            \item Proof on page 184.
        \end{itemize}
    \end{theorem}
    \begin{theorem}
        \textbf{Schröder-Bernstein Theorem} If $A$ and $B$ are sets with $|A| \leq |B|$ and $|B| \leq |A|$, then $|A| = |B|$. In other words, if there are one-to-one functions $f$ from $A$ to $B$ and $g$ from $B$ to $A$, then there is a one-to-one correspondence between $A$ and $B$.
    \end{theorem}
    \subsection{Matrices}
    \stepcounter{section}
    \section{Number Theory}
    \subsection{Divisibility and Modular Arithmetic}
    \subsection{Integer Representations and Algorithms}
    \subsection{Primes and Greatest Common Divisors}
    \subsection{Solving Congruences}
    \subsection{Applications of Congruences}
    \section{Induction and Recursion}
    \subsection{Mathematical Induction}
    \subsection{Strong Induction and Well Ordering Principle}
    \section{Counting}
    \subsection{Basics of Counting}
    \stepcounter{subsubsection}
    \subsubsection{Basic Counting Principles}
    \begin{theorem}
        \textbf{Multiplication Rule}: Multiply the number of ways that $A$ can occur by the number of ways that $B$ can occur (where $A$ and $B$ are two events).
        \begin{itemize}
            \item $|A_1 \times A_2 \times \dots \times A_n| = |A_1| \cdot |A_2| \cdot \dots \cdot |A_n|$
        \end{itemize}
    \end{theorem}
    \begin{theorem}
        \textbf{Sum Rule}: Add the number of ways that $A$ can occur to the number of ways that $B$ can occur (where $A$ and $B$ are two events).
        \begin{itemize}
            \item $|A_1 \unite A_2 \unite \dots \unite A_n| = |A_1| + |A_2| + \dots + |A_n|$ when $A_i \inter A_j =$ for all $i,j$.
        \end{itemize}
    \end{theorem}
    \stepcounter{subsubsection}
    \stepcounter{subsubsection}
    \subsubsection{Subtraction Rule (Inclusion-Exclusion For Two Sets)}
    \begin{theorem}
        \textbf{Subtraction Rule}: If $A$ can be done in either $n_1$ or $n_2$ ways, then the number of ways to do the task is $n_1 + n_2$ minus the number of ways to do the task that are common to the two different ways.
        \begin{itemize}
            \item $|A_1 \unite A_2| = |A_1| + |A_2| - |A_1 \inter A_2|$
        \end{itemize}
    \end{theorem}
    \subsubsection{Division Rule}
    \begin{theorem}
        \textbf{Division Rule}: There are $n/d$ ways to do a task if it can be done using a procedure that can be carried out in $n$ ways, and for every way $w$, exactly $d$ of the $n$ ways correspond to way $w$.
        \begin{itemize}
            \item Useful when it appears that a task can be done in $n$ different ways, but it turns out that for each way of doing the task, there are $d$ equivalent ways of doing it. There are $n/d$ inequivalent ways to do the task.
        \end{itemize}
    \end{theorem}
    \subsection{Pigeonhole Principle}
    \subsubsection{Introduction}
    \begin{theorem}
        \textbf{Pigeonhole Principle}: If $k$ is a positive integer and $k+1$ or more objects are placed into $k$ boxes, then there is at least one box containing two or more of the objects.
    \end{theorem}
    \begin{corollary}
        A function $f$ from a set with $k+1$ or more elements to a set with $k$ elements is not one-to-one.
    \end{corollary}
    \subsubsection{Generalized Pigeonhole Principle}
    \begin{theorem}
        \textbf{Generalized Pigeonhole Principle}: If $N$ objects are placed into $k$ boxes, then there is at least one box containing at least $\ceil*{\df{N}{k}}$ objects.
    \end{theorem}
    Here are some proofs using the pigeonhole principle:
    \begin{example}
        \textbf{Show that for every integer $n$ there is a multiple of $n$ that has only 0s and 1s in its decimal expansion.}
        \begin{proof}
            Let $n$ be a positive integer. Consider the $n+1$ integers $1,11,111,\dots,11\dots 1$ (where the last integer in this list is the integer with $n+1$ 1s in its decimal expansion). Note that there are $n$ possible remainders when an integer is divided by $n$. Because there are $n+1$ integers in this list, by the pigeonhole principle, there must be two with the same remainder when divided by $n$. The larger of these integers less the smaller one is a multiple of $n$, which has decimal expansion with only 0s and 1s.
        \end{proof}
    \end{example}
    \begin{example}
        \textbf{How many cards must be selected from a standard deck of 62 cards to guarentee that:}
        \begin{enumerate}[a)]
            \item at least three cards are of the same suit?
            \item at least three hearts are selected?
        \end{enumerate}
        \begin{proof}
            \textbf{a)} Suppose there are 4 boxes, one for each suit, and as cards are selected they are placed in their respective box. Using the generalized pigeonhole principle, we see that if $N$ cards are selected, there is at least 1 box contaning at least $\ceil*{N/4}$ cards. Thus, we know that at least 3 cards of 1 suit are selected if $\ceil*{N/4} \geq 3$. The smallest integer $N$ to satisfy this inequality is $2\times 4+1=9$, so we must select at least 9 cards to guarentee that at least 3 cards are of the same suit.
        \end{proof}
        \begin{itemize}
            \item Note that if 8 cards are selected, it is possible to have 2 cards of each suit, so more than eight cards are needed.
        \end{itemize} 
    \begin{proof}
        \textbf{b)} We do not use the generalized pigeonhole principle because we want to make sure that there are 3 hearts, not just 3 cards of a suit. Note that in the worst case, we can select all the clubs, diamonds, and spades, 39 cards in all, before we select a single heart. The next 3 cards will all be hearts, so we may need to select 42 cards to get 3 hearts.
    \end{proof}
    \end{example}
    \subsubsection{Some Elegant Applications of the Pigeonhole Principle}
    \begin{example}
        During a month with 30 days, a baseball team plays at least one game a day, but no more than 45 games. Show that there must be a period fo some number of consecutive days during which the team must play exactly 14 games.
        \begin{proof}
            Let $a_j$ be the number of games played on or before the $j$th day of the month. Then $a_1, a_2, \dots, a_{30}$ is an increasing sequence of distinct positive integers, with $1 \leq a_j \leq 45$. Moreover, $a_1 + 14, a_2 + 14, \dots, a_j + 14$ is also an increasing sequence of distinct positive integers, with $15 \leq a_j + 14 \leq 59$. \\

            The 60 positive integers $a_1, a_2, \dots, a_{30}, a_1 + 14, a_2 + 14, \dots, a_j + 14$ are all less than or equal to 59. Hence, by the pigeonhole principle two of these integers must be equal. Because the integers $a_j, j = 1,2,\dots, 30$, are all distinct and the integers $a_j+14, j= 1,2,\dots,30$ are all distinct, there must be indices $i$ and $j$ with $a_i = a_j + 14$. This means that exactly 14 games were played from day $j+1$ to day $i$.
        \end{proof}
    \end{example}
    \begin{example}
        Show that among any $n+1$ positive integers not exceeding $2n$ there must be an integer that divides one of the other integers.
        \begin{proof}
            Write out each of the $n+1$ integers $a_1, a_2, \dots, a_{n+1}$ as a power of 2 times an odd integer. In other words, let $a_j=2^{k_j}q_j$, for $j=1,2,\dots n+1$, where $k_j$ is a nonnegative integer and $q_j$ is odd. The integers $q_1, q_2, \dots, q_{n+1}$ are all odd positive integers less than $2n$. Because there are only $n$ odd positive integers less than $2n$, it follows from the pigeonhole principle that two of the integers $q_1, q_2, \dots, q_{n+1}$ must be equal. Therefore, there are distinct integers $i$ and $j$ such that $q_i = q_j$. Let $q$ be the common value of $q_i$ and $q_j$. Then $a_i = 2^{k_i}q$ and $a_j = 2^{k_j}q$. It follows that if $k_i < k_j$, then $a_i$ divides $a_j$; while if $k_i > k_j$, then $a_j$ divides $a_i$. In either case, there is an integer that divides one of the other integers.
        \end{proof}
    \end{example}
    \begin{theorem}
        Every sequence of $n^2 + 1$ distinct real numbers contains a subsequence of $n+1$ that is either strictly increasing or strictly decreasing.
    \end{theorem}
    \subsection{Permutations and Combinations}
    \stepcounter{subsubsection}
    \subsubsection{Permutations}
    \begin{definition}
        A \textbf{permutation} of a set $S$ is an ordering of the elements of $S$.
    \end{definition}
    \begin{theorem}
        If $n$ is a positive integer and $r$ is an integer with $1 \leq r \leq n$, then there are:
        \begin{equation*}
            P(n,r) = n(n-1)(n-2)\cdots(n-r+1)
        \end{equation*}
        $r$-permutations of a set of $n$ \textbf{distinct} elements.
    \end{theorem}
    \begin{corollary}
        If $n$ and $r$ are integers with $0 \leq r \leq n$, then: 
        \begin{equation*}
            P(n,r) = \frac{n!}{(n-r)!}
        \end{equation*}
    \end{corollary}
    \subsubsection{Combinations}
    \begin{definition}
        An $r$-combination of a set $S$ is a subset of $S$ with $r$ elements.
    \end{definition}
    \begin{theorem}
        The number of $r$-combinations of a set with $n$ elements, where $n$ is a nonnegative integer and $r$ is an integer with $0 \leq r \leq n$, is:
        \begin{equation*}
            C(n,r) = \frac{n!}{r!(n-r)!}
        \end{equation*}
    \end{theorem}
    \begin{corollary}
        Let $n$ and $r$ be nonnegative integers with $r \leq n$. Then:
        \begin{equation*}
            C(n,r) = C(n, n-r)
        \end{equation*}
    \end{corollary}
    \begin{definition}
        \textbf{Combinatorial Proof}: If this is on the final, doomed. Refer to Homework 3 (Practice Exam 3) Question 13 Part B for an example. Page 438 uses this method to prove the Binomial Theorem.
    \end{definition}
    \subsection{Binomial Coefficients and Identities}
    \subsubsection{Binomial Theorem}
    \begin{theorem}
        Let $x$ and $y$ be variables, and let $n$ be a nonnegative integer. Then:
        \begin{equation*}
            (x+y)^n = \sum_{j=0}^n \binom{n}{j}x^jy^{n-j} = \binom{n}{0}x^ny^0 + \binom{n}{1}x^{n-1}y^1 + \cdots + \binom{n}{n}x^0y^n
        \end{equation*}
    \end{theorem}
    \begin{corollary}
        Let $n$ be a nonnegative integer. Then:
        \begin{equation*}
            \sum_{k=0}^n \binom{n}{k} = 2^n
        \end{equation*}        
    \end{corollary}
    \begin{corollary}
        Let $n$ be a positive integer. Then:
        \begin{equation*}
            \sum_{k=0}^n (-1)^k \binom{n}{k} = 0
        \end{equation*}
    \end{corollary}
    \begin{corollary}
        Let $n$ be a nonnegative integer. Then:
        \begin{equation*}
            \sum_{k=0}^n 2^k \binom{n}{k} = 3^n
        \end{equation*}
    \end{corollary}
    \subsubsection{Pascal's Identity}
    \begin{theorem}
        \textbf{Pascal's Identity}: Let $n$ and $k$ be positive integers with $n \geq k$. Then:
        \begin{equation*}
            \binom{n+1}{k} = \binom{n}{k-1} + \binom{n}{k}
        \end{equation*}
    \end{theorem}
    \subsubsection{Other Identities Involving Binomial Coefficients}
    \begin{theorem}
        \textbf{Vandermonde's Identity}: Let $m,n,r$ be nonnegative integers, $r < m,n$. Then:
        \begin{equation*}
            \binom{m + n}{r} = \sum_{k=0}^r \binom{n}{k}\binom{m}{r-k}
        \end{equation*}
    \end{theorem}
    \begin{corollary}
        If $n$ is a nonnegative integer, then:
        \begin{equation*}
            \binom{2n}{n} = \sum_{k=0}^n \binom{n}{k}^2
        \end{equation*}
    \end{corollary}
    \begin{theorem}
        Let $n$ and $r$ be nonnegative integers with $r \leq n$. Then:
        \begin{equation*}
            \binom{n + 1}{r + 1} = \sum_{j=r}^n \binom{j}{r}
        \end{equation*}
    \end{theorem}
    \subsection{Generalized Permutations and Combinations}
    \stepcounter{subsubsection}
    \subsubsection{Permutations with Repetition}
    \begin{theorem}
        The number of $r$-permutations of a set of $n$ objects \textbf{with repetition} is:
        \begin{equation*}
            P_r(n) = n^r
        \end{equation*}
    \end{theorem}
    \subsubsection{Combinations with Repetition}
    \begin{itemize}
        \item STARS AND BARS
    \end{itemize}
    \begin{theorem}
        There are $C(n+r-1, r) = C(n+r-1, n-1)$ $r$-combinations from a set of $n$ elements \textbf{with repetition}.
    \end{theorem}
    \begin{itemize}
        \item $n$ stars and $r$ bars. Total positions is $n+r-1$. Number of ways to place $r$ bars is $C(n+r-1, r)$.
        \item Recall that we can have restrictions for each bar. \textbf{At least: Subtract from $n+r-1$ the number of stars. At most, subtract the complement.} 
    \end{itemize}
    \subsubsection{Permutations with Indistinguishable Objects}
    \begin{theorem}
        The number of different permutations of $n$ objects where there are $n_1$ indistinguishable objects of type 1, $n_2$ indistinguishable objects of type 2, \ldots, $n_k$ indistinguishable objects of type $k$ is:
        \begin{equation*}
            \frac{n!}{n_1!n_2!\cdots n_k!}
        \end{equation*}
    \end{theorem}
    \begin{itemize}
        \item Proof on Page 450.
    \end{itemize}
    \subsubsection{Distributing Objects into Boxes}
    \begin{theorem}
        The number of ways to distribute $n$ \textbf{distinguishable objects} into $k$ \textbf{distinguishable boxes} so that $n_i$ objects are placed into box $i, i = 1, 2, \ldots, k$ is:
        \begin{equation*}
            \frac{n!}{n_1!n_2!\cdots n_k!}
        \end{equation*}
    \end{theorem}
    \begin{figure}[H]
        \centering
        {\renewcommand{\arraystretch}{2}
        \begin{tabular}{|l|c|}
            \hline
            Situation & Formula \\
            \hline
            $n$ Distinguishable Objects and $r$ Boxes & $\df{n!}{n_1!n_2!\cdots n_k!}$ \\
            $n$ Indistinguishable Objects and $r$ Distinguishable Boxes & $\displaystyle\binom{n + r - 1}{r}$ \\
            $n$ Distinguishable Objects and $r$ Indistinguishable Boxes & Give up. Start writing everything out. \\
            \hline
        \end{tabular}}
        \caption{Distributing Objects into Boxes}
    \end{figure}
    \section{Probability}
    \subsection{Introduction to Discrete Probability}
    \subsection{Probability Theory}
    \subsection{Bayes' Theorem}
    \begin{theorem} \textbf{Bayes' Theorem}: Suppose that $E$ and $F$ are events from a sample space $S$ such that $p(E) \neq 0$ and $p(F) \neq 0$. Then:
        \begin{equation*}
            p(F \mid E) = \frac{p(E \mid F)p(F)}{p(E \mid F)p(F) + p(E \mid \overline{F})p(\overline{F})}
        \end{equation*}
    \end{theorem}
    \subsection{Expected Value and Variance}
    \stepcounter{subsubsection}
    \subsubsection{Expected Values}
    \begin{definition}
        The \textbf{expected value} of the random variable $X$ on the sample space $S$ is:
        \begin{equation*}
            E(X) = \sum_{s \in S} p(s)X(s)
        \end{equation*}
        The \textbf{deviation} of $X$ at $s \in S$ is: 
        \begin{equation*}
            d(s) = X(s) - E(X)
        \end{equation*}
    \end{definition} 
    \begin{theorem}
        If $X$ is a random variable and $p(X=r)$ is the probability that $X=r$, so that $p(X=r) = \displaystyle\sum_{s \in S, X(s)=r} p(s)$, then:
        \begin{equation*}
            E(X) = \sum_{r \in X(s)} p(X=r)r
        \end{equation*}
    \end{theorem}
    \begin{example}
        \textbf{Expected Value of a Die: }
        \begin{itemize}
            \item Let $X$ be the random variable that represents the number of spots on a die. Then $X$ is a random variable on the sample space $S = \{1,2,3,4,5,6\}$.
            \item Let $\displaystyle p(s) = \frac{1}{6}$ for each $s \in S$.
            \item Then $\displaystyle E(X) = \sum_{s \in S} p(s)X(s) = \sum_{s \in S} \frac{1}{6}X(s) = \frac{1}{6}\sum_{s \in S} X(s) = \frac{1}{6}\cdot 21 = \df{7}{2}$
            \item The expected value of $X$ is 3.5.
        \end{itemize}
        \label{ex:ev-die}
    \end{example} 
    \begin{theorem}
        The expected number of successes when $n$ mutually independent Bernoulli trials are formed, where $p$ is the probability of success on each trial, is:
        \begin{equation*}
            E(X) = np
        \end{equation*}
    \end{theorem}
    \subsubsection{Linearity of Expectations}
    \begin{theorem}
        If $X_i=1,2,\dots,n$ with $n$ a positive integer, are random variables on $S$, and if $a$ and $b$ are real numbers:
        \begin{enumerate}[(i).]
            \item $E(X_1 + X_2 + \dots + X_n) = E(X_1) + E(X_2) + \dots + E(X_n)$
            \item E(aX + b) = aE(X) + b
        \end{enumerate}
    \end{theorem}
    \stepcounter{subsubsection}
    \subsubsection{Geometric Distribution}
    \begin{definition}
        TA random variable $X$ has a \textbf{geometric distribution with parameter} $p$ if $p(X = k) = (1-p)^{k-1}p$ for $k = 1,2,\dots$, where $p$ is a real number with $0 \leq p \leq 1$.
    \end{definition}
    \begin{theorem}
        If the random variable $X$ has the geometric distribution with parameter $p$, then:
        \begin{equation*}
            E(X) = \frac{1}{p}
        \end{equation*}
    \end{theorem}
    \subsubsection{Independent Random Variables}
    \begin{theorem}
        The random variables $X$ and $Y$ on the sample space $S$ are \textbf{independent} if:
        \begin{equation*}
            p(X=r_1 \text{ and } Y=r_2) = p(X=r_1)p(Y=r_2)
        \end{equation*}
        or in words, if the probability that $X = r_1$ and $Y = r_2$ equals the product of the probabilities that $X = r_1$ and $Y = r_2$ for all numbers $r_1$ and $r_2$.
    \end{theorem}
    \begin{theorem}
        If $X$ and $Y$ are independent random variables on the sample space $S$, then:
        \begin{equation*}
            E(XY) = E(X)E(Y)
        \end{equation*}
    \end{theorem}
    \subsubsection{Variance}
    \begin{definition}
        Let $X$ be a random variable on a sample space $S$. The \textbf{variance} of $X$ is, denoted by $V(X)$ is:
        \begin{equation*}
            V(X) = \sum_{x \in S}(X(s) - E(X))^2p(s)=E(X^2) - E(X)^2
        \end{equation*}
        $V(X)$ is the weighted average of the square of the deviation of $X$. The \textbf{standard deviation} of $X$, denoted $\sigma(X)$, is:
        \begin{equation*}
            \sigma(X) = \sqrt{V(X)}
        \end{equation*}
    \end{definition}
    \begin{example}
        \textbf{Variance of the Value of a Die} \\
        We have $V(X) = E(X^2) - E(X)^2$. From \hyperref[ex:ev-die]{Example 7.4.2.1}, we have $E(X) = 7/2$. To find $E(X^2)$ note that $X^2$ takes the values $i^2, i=1,2,\dots,6$, each with probability $\frac{1}{6}$. Thus:
        \begin{equation*}
            E(X^2) = \frac{1}{6}\sum_{i=1}^6 i^2 = \frac{1}{6}\cdot 91 = \frac{91}{6}
        \end{equation*}
        Thus:
        \begin{equation*}
            V(X) = \frac{91}{6} - \paren*{\frac{7}{2}}^2 = \frac{35}{12}
        \end{equation*}
    \end{example}
    \begin{corollary}
        If $X$ is a random variable on a sample space $S$ and $E(X) = \mu$, then:
        \begin{equation*}
            V(X) = E(X - \mu)^2
        \end{equation*}
    \end{corollary}
    \begin{theorem}
        \textbf{Variance of a Bernoulli Trial} \\
        Because $X$ takes only the values $0$ and $1$, it follows that $X^2(t) = X(t)$. Hence:
        \begin{equation*}
            V(X) = E(X^2) - E(X)^2 = p - p^2 = p(1-p) = pq
        \end{equation*}
        Where $p$ is the probability of success on a single trial, $q$ is the probability of failure.
    \end{theorem}
    \begin{theorem}
        If $X$ and $Y$ are independent random variables on the sample space $S$, the $V(X+Y) = V(X) + V(Y)$. Furthermore, if $X_i, i=1,2,\dots,n$, with $n$ a positive integer, are pairwise independent random variables on $S$, then:
        \begin{equation*}
            V(X_1 + X_2 + \dots + X_n) = V(X_1) + V(X_2) + \dots + V(X_n)
        \end{equation*}
    \end{theorem}
\end{document}